{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3552f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "# Set the path to the main folder containing the CT scan folders\n",
    "folder_path = \"ct_scans/\"\n",
    "\n",
    "# Define the categories and their corresponding labels\n",
    "categories = [\"benign\", \"malignant\", \"normal\"]\n",
    "labels = [0, 1, 0]\n",
    "\n",
    "# Initialize empty lists to store the images and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Loop through the categories\n",
    "for category, label in zip(categories, labels):\n",
    "    # Set the path to the current category folder\n",
    "    category_path = os.path.join(folder_path, category)\n",
    "    \n",
    "    # Loop through the files in the current category folder\n",
    "    for file_name in os.listdir(category_path):\n",
    "        # Set the path to the current file\n",
    "        file_path = os.path.join(category_path, file_name)\n",
    "        \n",
    "        # Load the image in RGB format\n",
    "        image = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        # Append the image and its corresponding label to the lists\n",
    "        X.append(image)\n",
    "        y.append(label)\n",
    "\n",
    "# Convert the lists to NumPy arrays for further processing\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print ('The shape of X is: ' + str(X.shape))\n",
    "print ('The shape of y is: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))\n",
    "print(\"Validation set size:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f07c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 images\n",
    "for i in range(5):\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a86ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the image data to a range of 0 to 1\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_val = X_val.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149614dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "tf.random.set_seed(1234)\n",
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(224, 224, 3)),\n",
    "        layers.Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a147bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and store the training history\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=40, validation_data=(X_val, y_val))\n",
    "\n",
    "# Get the training and validation accuracy/loss history\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Plot the accuracy\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the loss\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36464404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy on the testing set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea5de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Convert predictions from one-hot encoded format to class labels\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Convert the confusion matrix to a Pandas DataFrame for better visualization\n",
    "cm_df = pd.DataFrame(cm, index=['Benign', 'Malignant'], columns=['Benign', 'Malignant'])\n",
    "\n",
    "# Plot the confusion matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bb5b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
